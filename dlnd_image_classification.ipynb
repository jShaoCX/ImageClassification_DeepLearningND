{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAHF9JREFUeJzt3UmPZOl1HuAvxsyMrKzKqsqau6rYA5vNbropkjJJmYIs\nUIBXWtn+BV7YO/8Yr73wymtDNAwIggwSMEmBNMeW2Wz2VOzumquyco6M2QttzI2Bc5gChYPn2Z88\nEd+9cd+8q7ezWq0aAFBT9w/9AQCAfzyCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANA\nYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh/T/0B/jH8l/+w79fZebGx9PwTK+f\n+3+pc/tGeGZvtJHa9faFYWruk1/+LDzznR/+PLVrbzILz/R6ybPvdFJzg7X18MylKzupXec34t/t\n83eupHb9+be+Hp6Zz+LXq7XWnu0fpeYGWxfDM+9+8NvUrr/97g/jQ8nnwNogN3dhMAjPDPuL1K5p\n4lrPZ7nfWFstU2NrvbXwzMkq/rxvrbUXp/F46eZ+Lu073/+75EH+P7t/3z8AAPzTJegBoDBBDwCF\nCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGFl2+te3P84NddfxJuT\nBv1UUV67v5qEZ94f5yqQ3v7iK6m55TT+Ga/t5NraNlLfLXf22fa6k0n8PPZ3X6R2HXXiTWOT03Fq\n15e/+o3wzOzkNLXr2fPceVxbjzc3LqcHqV0ba/H7atlyrWtXt86l5r70ymvhmadP7qd2jceH4Zmj\no1xLYevGW/laa22tPw/P3Lx+IbVrNrwanvngV/dSu86CN3oAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9\nABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUFjZUpuPT9dScyfj/fDMsJMr92iLeKFCtzNMrXr2\n28epuZ88+Cw88+snudKS1SReSpEtp1lfX0/NzebxopnWzf0/vb4Rv4f3xrlilR+983545sblXCHI\nZJ67ZpkCo7XkE24wSHzG3NG3L7z6amruc3fuhme2t0apXY8e3gvPLGe55+K5izdSc4tBvPRotJYr\n3rm5Ey8i+rSXO/uz4I0eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgsLLtdeNeriFrtxtvJ+ssJqldl/vx4z93/mJq1+lxvJWvtdb2DuPf7eB0ltq1\nSpz9YpFok2ut9ZKfsZ/533gWb11rrbXjafzsz61yu370i1+GZ15/7bXUrjdevZOa6w/j7V+f+1yu\nGe54OQjPPH74NLXr4HCcmmvrm+GRP/6zt1Orfv7j74VnxvN4G2VrrR3Oci1vz4/jz8ZL41zD3q3e\nYXjm9Cjb2vj780YPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANA\nYYIeAAorW2qz1tlNzd0YxYsYtlu8AKO11i5d3AjPfLyKlym01trmxjI1t9aJl6SMOrnbara5Fp+Z\n58ppTie5IqJF4n/jjVGupGO4Fr+vrt++kdp186Xb4ZlnR7lCkEcHuRKXb3zj6+GZ3cePUrv+9b/5\nVnjmf/z3v07t+uEP/i41d+dLXw3PfPvtr6V2fXj/o/DMx9//cWrX/nQrNXc0jz/jvvjP42fYWmvj\n2YvwzM7OemrXWfBGDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNAD\nQGGCHgAKE/QAUFjZ9rrhZu6rvbJ1NTzz8iq368Iw0Wa0/1lq12g73gzXWmvHw5PwzHKwSO364z+K\nN0lduxq/Xq219tEHH6TmPv3kfnim28u1G67m8Xa49W7u7P/kG/Gzfxq/NVprrf3oe99Nzb333p3w\nzGKc/JCbF8Mje8e5RsSjWe5964OHz8Mzx8teatfxPP4Zn+zlzmOyfi419/m7r4Rntq/dTO16+jx+\n9t/+9lupXWfBGz0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCF\nCXoAKEzQA0BhZdvrjqa5xrALvc3wzOzZi9SuT/fiTWh/+uU3UrvG0+PU3K1lfGZ9tErt+uZ2/Ozf\nvLKT2nWyzH3GZ2vxFsCT/dz9sZjGZ/rTw9Suu598HJ7Z2Jundl26sp2am/39z8Iz2ebAH/7q3fDM\new8epHadznMtb/c/iTdZPnn+NLXr61/5Znjm7vbt1K7/9F//W2puOn4UnvnJj5+ldj1+/GF45qt/\nkXt2nwVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGg\nsLKlNld666m5W60Xnjl/fiu16+cv4qUULyb7qV13r99Izf3bJy+HZwYHuQKdy+/Hz2Ptw4epXYvl\nLDX3uU58ZrBIDLXWuv34Pbzo5EpcJj/6aXjmQrKMZbkTLy9qrbXFPNGwdLBI7TrfOxeemRzn7vtL\n8UdOa6210Wocnjl49NvUrltffD08s7WZewZ//dVbqbkn+/EWqEdHJ6ldJye74ZmP3n8/tesseKMH\ngMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAorGx7\n3Rtbo9Tc5vNn4ZleN9Gq1Vp7/aWXwjOHj5+mdrVVrkHtVmcVnhkNc7t6iUaozjL++VprLd5z9Q8m\n3cT/xsO11K7BKv7d+pmGt9baoBtv85tt5WrXVie51rv5JH4ei5a7F69143fItzdyrXzTzjA1t7h5\nLTyzfu9eatdJ5iMmWz3feuO11NyNk/g1uzGbp3a9/urN8MxrO/FGxLPijR4AChP0AFCYoAeAwgQ9\nABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFFa21Gb3wUepuck8XoIx7uWKRE4u\nxEsONk7i5SOttXb67oepuUVvEZ6Zb+Zuq24vXkqxlixx6bT11Nw8UQ60WOY+42owiM+kNuXm+ldf\nSe3a2su9X5wmLtn07sXUrovzo/DM5mmuKmm+lytWOXqyH545efD91K6H//sX4Znzb72e2vX8Ua64\nazq6FJ6Zj1Or2snzF+GZg0G2Suv3540eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh\ngh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtdc+P9lJznx6fhmfmy1z71LBzPTwzuriT2vV8fJiau95b\nC89snOb+f1wcxJv5JtNcm1/byZ3j5uuvhWdOE01orbV29OwgPLO2jLfrtdZabzIJz0ye5u6ptpZr\nlOtsx9se+51cn9/yIP4c2Hgr1+bXhvHv1Vproyfx6rXj+/dTu/Z+/UF4ZvnJ49SurUtbqbnd7XhL\n5PNHud/mwyefhWdeHt5I7ToL3ugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGg\nMEEPAIUJegAoTNADQGGCHgAKK9te9+I03j7VWmuPTuJtRrOD49SunWtXwjOr21dTu9Yu5hqh1g7i\nzXz9B09Tu6ZHJ+GZoxZvrGqttcW5jdTc4O6d8Ey/s0jt2tyOn8fsN5+kds0SLYCn3Vxz4NafvZma\nO9l7Fh9679epXW2eeAd6mPh8rbXJMte0Obh+Mzxz/V9+M7VrbaMXntn9zYepXdsn8V2ttXbhbrxp\n85NHuYa9jV68FXEwGKZ2nQVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgsLKlNrdvv5Sa6358PzyzMU6taotpvBhhrTNI7XpxfJCa+8Gnn4Vnbp4epna9\n0eIHOUmUsbTW2vh+/Dq31tr0p7+K72rx69xaa51bt8Izp69fT+06mY/CM2+/miunOe6eS82NH9wL\nzwz3c+VW8/PxApLpJ8lCoce5UqzB1SfhmZNruVKswaUL4ZmLf/HV1K69Tx+m5rZ34mU4Xz13N7Xr\nb/7Xi/DM2na8xOyseKMHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm\n6AGgMEEPAIUJegAorGx73fWb11Jzh/efhWdGFzupXa2zFh4ZdHO7Hj57npr7z7/4P+GZL1zOtZP9\nx/XN8Mwo+a/q6vgoNbf7Try9bvdKvPmrtdY+msRbzabJprybr98Mz9y5mPte04ePU3PnEq1mneU0\ntasdxn9na92N1KqD8UlqbvHRR+GZ1YNHqV0vtuLPqs0v5BpEb778amru9FH8vroyij9zWmvtK196\nLTxz++XceZwFb/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAU\nJugBoLCypTb7ixepuf5qPzwz6OeOcdqLF5DszcepXbvjXNnJfBX/bgeDXLnH/cEoPLO9mqd2Tbu5\nudVqEp7ZX+ZKSz57Ei+1Od9dT+16kbhkf3X/r1K7vnDrVmru1Uvx73Z57Xpq1/G9++GZxTh+vVpr\nbbXI3YsvXjxN7Mo9B6br8VKb2X68IKy11qa/fD81N0oUOk3WB6ldd998Kzwze/Db1K6z4I0eAAoT\n9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtdcPV\nMjXXX87CMzvdXAPStBdvrerPpqldJ6e587h15Up45qWXb6d23T9KNPOtcm1cw2RrVWce/8lMl/HG\nu9Zau3F5JzzTzxWhtYOnj8Izq91cK9+D57mWt/3RMDxzZxL/PbfWWvdZvL2ujXOH353n3rfG8/g5\nnixyz49VohVxNO6kdj28/1lqbtSJ7zue567Z9iQ+t/P266ldZ8EbPQAUJugBoDBBDwCFCXoAKEzQ\nA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAorGypzcZ4lJp7ML8QnrnaPU3tujjeC8/0\nnzxM7ZofvkjNffHNl8Mzd77w+dSu3V+8F5650emldrVBrgxnsIr/b7xxlCtx6bf4ZxyNNlK7fvPh\nvfDMznHuPeGVz11KzX02jBfUPP4g93vZONwNz3TmuXuqs8jdw6eJUqxpN3fNpsfxXbuLw9Su0eh8\nau5wGi+POp7krtnu/cfhmf6d66ldZ8EbPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeA\nwgQ9ABQm6AGgMEEPAIUJegAoTNADQGFl2+v2j+NNV6219t39eEvT/HJqVfvWchqe2XjyKLVrfXaS\nmvvK174dnrl5+7XUru/86J3wzP4k1xy46Ofuj1miLW9j1UntOv0sfq17l3LNcK9c3AnPnC72U7v6\nm8PU3Nt/+vXwzG680Owf5n7yJDwzWeaa0Jb9tdTcOHFfbW4mH1Ybm+GR8TDXyre8fDE1d9ri+x49\njbcUttba/t6z8MyLX7+f2vWXqanf5Y0eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh\ngh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtddODB6m5D54/Ds+MZ7k2ru2X4o1hXx7kWte2+vFWvtZa\ne/n27fDM+XO5BrXJIt7mNzmJz7TW2nCwSM2druL7ht3c/TGcxq/ZeDfXxtXtxx8Fy16ure3x81wD\n44t3fxWeGa3nGtQO18/FZzZGqV2Tc1upuePj4/DMaCf329ydxlsiD+e531h3Nk7NPXx0FN+1Hm/l\na621g1n8ObB5kGt7PAve6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8A\nhQl6AChM0ANAYWVLbf7V3VxZwdPdeJnFjz8+Se36m3vxkoONV3Lfa3RuLTW31YsXdcwO4wUYrbW2\n6MRLMI4nuV3rvdytv+gl/jfu5P6fXnbjc7vH8WKP1lpbncYLdIbHubOf7eWKiFYffhKeGSXfZaaj\n8+GZd+aT1K57z56k5taX8ZnhMlcYM1iP/146s05q1+lerpjpeBUvB+qfG6R2LQbx73b34nZq11nw\nRg8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFBY\n2fa612/mvtq/G90Jz9xeu5/a9T/fizeN/e29WWrXH929mZo7+vDj8Mxe8v/H3jJex7U3zTUHXhnF\nm65aa22x6oVnZsvcNXu6ip/Hs1G8fbG11k778fa6rU7uN7Z5IXf2y2n8M7bnB6lda2vxlsjPTnPN\ncM8Xq9Tc9UG8eW20mbs/tjbj57Ea59oNn01z59jvxZ8Fvd3c8+NLq2F45txh7jlwFrzRA0Bhgh4A\nChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCypbaTJJlJ5fWO+GZ\nP3l9J7Xr2XG8tOQn9/dTu959/CI19/lEUcd0mLutVsv4/52Hp5Pcrkm8lKK11gbr8e+2WuZKS1pi\nbmNtPbXqcBUvIDm4cy216/Jbb6TmevGfS3vnr7+X2nU7cV+9dPFKalebTFNj6/34gezPcoUxx8/j\nz9PryYKlmzuXU3PDbvy3OdjNPU/vHsYLyW5vb6d2nQVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoA\nKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIWVba/r9HJfrTOPt1bd2M41hv2Lly+EZw6m\n8Zax1lq7t5dr8zvpxdv8rt6+ndrVG47CM6fzXDPc6eFhaq4/W4RnhoON1K743dHa/PHT1K7zi3l4\nZnKQu6d2Z4kautba9sWL8ZlO7l1mcBr/brc2N1O7hsn3rc7mWnxmkPuM3aN4w961fvz33FpriQLR\n1lpr3Un8t3mSfA5c6MXvj1fv5HLiLHijB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQ\nmKAHgMIEPQAUJugBoDBBDwCFCXoAKKxse91qlatAWi0T7WTLeONda629eSl+/E9vnEvtOp7kPuN8\nHG/L27l8JbVr/Vy8r21vmWuvm01nqbl5Ym7SyzUOdju98Mz55L/umV6t6cF+btlp7jxWj56EZ15q\nuefAoBdv89sa587jai/Xbvgi0Ui5thVvAGytteUsfmPNT/ZSuw4muVbERHldW06OU7tuvHk1PPPy\nndxz8Sx4oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8A\nhZUttVl2cv/DLFq8SKTNcwUpF/rxwo2v3N5J7Xp+uJuamz5+GJ6ZHeeKIoab8XKP0+R1nq1yc91l\n/FovZom2jdZaZxG/P+bJ85gOMuUv8eKX1lrrzHPnsegN40PdXKnNYh7/bqtkWc/6YpCaW82m4ZlH\n67mimdla/OyXa6lVbbCZO4+Tk/h5DFfL1K4rd66HZ9b7ifv3jHijB4DCBD0AFCboAaAwQQ8AhQl6\nAChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKKxse91wYzM111sfhWeme0epXZlW\ns5vb8c/XWmv/bD/XrPXu3uPwzKMHn6R2HYwPwjNHy1z71Gk39z/uYLkKz8xXuba27ir+8zzu5Nra\nTlbxuX7yPWE5yV2z5SR+D3eS7XUtcZ1P+7nrvEw05bXW2nHmM65NUrtaN/7d1ge5+rrlIt5C11pr\nm8v4d3vt2lZq18Vh/OxPnueaA3Of8Hd5oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QA\nUJigB4DCBD0AFCboAaAwQQ8AhZUttWndXmqs0xmEZ/obqVXttDsLzwwSZQqttXbnRq4M5+PP4gUT\n08lxatdiGd+1N88VYDzr5G79rV78vuqscteskyio2c/1xbRH03hpSbeTe0/oJQp0srJvMoMWv86P\nl/Hfc2ut7bdcGc5R4lrfSpb8bCcKuHq7h6ld1/rrqbmv3b4ennn1du7hPRrHi8wmybIepTYAwP+X\noAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhdVtr1vm\n/oeZjE/CM9k2rk6iSWo1zTVkndvcTM3tnI83Lu0+fZLadfgoPrffy13nHySbxi4miujOJxoRW2tt\nM9FeN+vmmvIO5vG502TrWra7rteNX+thom2wtdZGqU+Z29Xv5CoHR4lrvZzNU7umi/h5bCTvjwvn\ncp+xzQ7CI0cvcmd/cD7+m+7Mc8+cndTU7/JGDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm\n6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUFjZ9rrFMtfitUrMdZINasP+MDyzGucakFruONrVzfhn\n/Ok7f5/a9fzB0/DMvJO7hZ8mO9QO5vE2v9Ei2U6W+IhryXtxNYxf526iTa611jqJVr7WWuv3441h\ni1WynWwR/53N57m2tlXyMw4zx59sr1sm7qtuP/fQWbbcM27vaC8801vlzmOtuxWe6Sz/cHHrjR4A\nChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFFa21KY7iBdg\ntNbaINHD0EkWxnR6ieNf5IozFsdHqbkbW6PwzOVB7jMOTsfhmfPLXEHKaSf3P243MTfv50pLjpfx\nuXHyXmyJEpfePLeskywU6iYKhVarZLlVJ372uW/V2qDTy80lnh8byfv+XGJss5N8DuTGWmvxwcn4\nOLUp8zgddePP0rPijR4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJig\nB4DCBD0AFCboAaCwuu11/dxX660S//uscu1kLdVel2vl63dz3VrnOvHGsD9762Zq1/5JfNfPPnmW\n2vVsMk/NnS7jbWiTZK/ZMnF/LJP/uy8S36ubrG3sJGveut1sNV9cL9Hy1k9+vI1u7lk16safBVv9\n3OFvdePPuMvJdBklb5BBi/+mh8l7arWI7zpNtHOeFW/0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAo\nTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaCwsqU2bbieHIyXFXRWyTaLRPHOfD5LrVomL3WmvOHG\nKLWq/eWXb4Vnrg1yhUIfPD5IzT0+jp//i3mupON02QvPTJK34rwTv86rRPFLa611e/Hv1VprvcRc\nsj+nDRIlP/1kt9VmptyqtbaWOP+1Tu5Dnu8twjMXkwU6m73cfbU+iJ9jP3crttks/hw46cTP8Kx4\noweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6ACis\ns8o2rwEA/+R5oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAw\nQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM\n0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh/xfkBwlHN40TWAAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2d205c1efd0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    return x/255.0\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    copy = np.zeros((len(x), 10))\n",
    "    for i in range(0,len(copy)):\n",
    "        copy[i][x[i]] = 1\n",
    "    return copy\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    "If you're finding it hard to dedicate enough time for this course a week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) to build each layer, except \"Convolutional & Max Pooling\" layer.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    "If you would like to get the most of this course, try to solve all the problems without TF Layers.  Let's begin!\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32,shape=[None,*image_shape],name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32,shape=(None,n_classes), name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32,name='keep_prob')\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "Note: You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer.  You're free to use any TensorFlow package for all the other layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    weights = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], int(x_tensor.shape[3]), conv_num_outputs],mean=mu,stddev=sigma))\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    conv_layer = tf.nn.conv2d(x_tensor, weights, [1,conv_strides[0],conv_strides[1],1], padding='SAME',name='Conv2D')\n",
    "    conv_layer = tf.nn.bias_add(conv_layer,bias)\n",
    "    conv_layer = tf.nn.relu(conv_layer,name='Conv2D_Relu')\n",
    "    \n",
    "    max_pool_layer = tf.nn.max_pool(conv_layer, ksize=[1,pool_ksize[0], pool_ksize[0],1], strides=[1,pool_strides[0],pool_strides[0],1], padding='SAME',name='MaxPool')\n",
    "\n",
    "    return max_pool_layer\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). You can use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    shape = x_tensor.get_shape().as_list()\n",
    "    return tf.reshape(x_tensor, [-1, shape[1]*shape[2]*shape[3]])\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). You can use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    weights = tf.Variable(tf.truncated_normal([x_tensor.get_shape().as_list()[1], num_outputs],mean=mu,stddev=sigma))\n",
    "    bias = tf.zeros(num_outputs)\n",
    "    \n",
    "    fc = tf.matmul(x_tensor, weights, name='FC_matmul')\n",
    "    fc = tf.add(fc, bias, name='FC_add')\n",
    "    \n",
    "    fc = tf.nn.relu(fc)\n",
    "    \n",
    "    return fc\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). You can use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for this layer.\n",
    "\n",
    "Note: Activation, softmax, or cross entropy shouldn't be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    weights = tf.Variable(tf.truncated_normal([x_tensor.get_shape().as_list()[1], num_outputs],mean=mu,stddev=sigma))\n",
    "    bias = tf.zeros(num_outputs)\n",
    "    \n",
    "    output = tf.matmul(x_tensor, weights, name='out_matmul')\n",
    "    output = tf.add(output, bias,name='out_add')\n",
    "    return output\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv1 = conv2d_maxpool(x, 6, (5,5), (1,1), (2,2), (2,2))\n",
    "    conv1 = tf.nn.dropout(conv1, keep_prob)\n",
    "    conv2 = conv2d_maxpool(conv1, 12, (5,5), (1,1), (2,2), (2,2))\n",
    "    conv2 = tf.nn.dropout(conv2, keep_prob)\n",
    "    conv3 = conv2d_maxpool(conv2, 18, (5,5), (1,1), (2,2), (2,2))\n",
    "    conv3 = tf.nn.dropout(conv3, keep_prob)\n",
    "    conv4 = conv2d_maxpool(conv3, 24, (5,5), (1,1), (2,2), (2,2))\n",
    "    conv4 = tf.nn.dropout(conv4, keep_prob)\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flat = flatten(conv4)\n",
    "    \n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fc1 = fully_conn(flat, 300)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "    fc2 = fully_conn(fc1,100)\n",
    "    fc2 = tf.nn.dropout(fc2, keep_prob)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    fin = output(fc2, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return fin\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    session.run(optimizer, feed_dict={x:feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    loss = session.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    val_acc = session.run(accuracy, feed_dict={x:valid_features, y:valid_labels, keep_prob:1.0})*100\n",
    "    test_acc = session.run(accuracy, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})*100\n",
    "    \n",
    "    print('LOSS: {0:.3f} TEST_ACC: {1:.3f}% VALIDACTION_ACC: {2:.3f}%'.format(loss, test_acc, val_acc))\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 60\n",
    "batch_size = 512\n",
    "keep_probability = 0.7 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  LOSS: 2.302 TEST_ACC: 11.149% VALIDACTION_ACC: 12.480%\n",
      "Epoch  2, CIFAR-10 Batch 1:  LOSS: 2.301 TEST_ACC: 10.135% VALIDACTION_ACC: 10.640%\n",
      "Epoch  3, CIFAR-10 Batch 1:  LOSS: 2.293 TEST_ACC: 10.473% VALIDACTION_ACC: 9.760%\n",
      "Epoch  4, CIFAR-10 Batch 1:  LOSS: 2.272 TEST_ACC: 14.189% VALIDACTION_ACC: 14.060%\n",
      "Epoch  5, CIFAR-10 Batch 1:  LOSS: 2.215 TEST_ACC: 18.919% VALIDACTION_ACC: 18.480%\n",
      "Epoch  6, CIFAR-10 Batch 1:  LOSS: 2.185 TEST_ACC: 17.230% VALIDACTION_ACC: 17.960%\n",
      "Epoch  7, CIFAR-10 Batch 1:  LOSS: 2.154 TEST_ACC: 16.554% VALIDACTION_ACC: 19.560%\n",
      "Epoch  8, CIFAR-10 Batch 1:  LOSS: 2.106 TEST_ACC: 20.270% VALIDACTION_ACC: 23.400%\n",
      "Epoch  9, CIFAR-10 Batch 1:  LOSS: 2.078 TEST_ACC: 24.324% VALIDACTION_ACC: 23.620%\n",
      "Epoch 10, CIFAR-10 Batch 1:  LOSS: 2.049 TEST_ACC: 25.000% VALIDACTION_ACC: 23.740%\n",
      "Epoch 11, CIFAR-10 Batch 1:  LOSS: 1.998 TEST_ACC: 28.716% VALIDACTION_ACC: 26.360%\n",
      "Epoch 12, CIFAR-10 Batch 1:  LOSS: 1.974 TEST_ACC: 30.068% VALIDACTION_ACC: 26.640%\n",
      "Epoch 13, CIFAR-10 Batch 1:  LOSS: 1.961 TEST_ACC: 29.392% VALIDACTION_ACC: 27.560%\n",
      "Epoch 14, CIFAR-10 Batch 1:  LOSS: 1.931 TEST_ACC: 28.716% VALIDACTION_ACC: 27.440%\n",
      "Epoch 15, CIFAR-10 Batch 1:  LOSS: 1.929 TEST_ACC: 27.365% VALIDACTION_ACC: 27.140%\n",
      "Epoch 16, CIFAR-10 Batch 1:  LOSS: 1.909 TEST_ACC: 30.068% VALIDACTION_ACC: 28.580%\n",
      "Epoch 17, CIFAR-10 Batch 1:  LOSS: 1.908 TEST_ACC: 27.365% VALIDACTION_ACC: 29.020%\n",
      "Epoch 18, CIFAR-10 Batch 1:  LOSS: 1.896 TEST_ACC: 30.405% VALIDACTION_ACC: 30.580%\n",
      "Epoch 19, CIFAR-10 Batch 1:  LOSS: 1.861 TEST_ACC: 30.743% VALIDACTION_ACC: 31.400%\n",
      "Epoch 20, CIFAR-10 Batch 1:  LOSS: 1.856 TEST_ACC: 31.081% VALIDACTION_ACC: 33.080%\n",
      "Epoch 21, CIFAR-10 Batch 1:  LOSS: 1.861 TEST_ACC: 31.757% VALIDACTION_ACC: 32.480%\n",
      "Epoch 22, CIFAR-10 Batch 1:  LOSS: 1.876 TEST_ACC: 30.405% VALIDACTION_ACC: 32.200%\n",
      "Epoch 23, CIFAR-10 Batch 1:  LOSS: 1.856 TEST_ACC: 33.108% VALIDACTION_ACC: 33.220%\n",
      "Epoch 24, CIFAR-10 Batch 1:  LOSS: 1.822 TEST_ACC: 33.446% VALIDACTION_ACC: 33.800%\n",
      "Epoch 25, CIFAR-10 Batch 1:  LOSS: 1.790 TEST_ACC: 34.122% VALIDACTION_ACC: 34.380%\n",
      "Epoch 26, CIFAR-10 Batch 1:  LOSS: 1.826 TEST_ACC: 33.784% VALIDACTION_ACC: 33.320%\n",
      "Epoch 27, CIFAR-10 Batch 1:  LOSS: 1.821 TEST_ACC: 31.757% VALIDACTION_ACC: 34.300%\n",
      "Epoch 28, CIFAR-10 Batch 1:  LOSS: 1.757 TEST_ACC: 32.770% VALIDACTION_ACC: 36.460%\n",
      "Epoch 29, CIFAR-10 Batch 1:  LOSS: 1.752 TEST_ACC: 34.122% VALIDACTION_ACC: 35.800%\n",
      "Epoch 30, CIFAR-10 Batch 1:  LOSS: 1.741 TEST_ACC: 34.459% VALIDACTION_ACC: 37.060%\n",
      "Epoch 31, CIFAR-10 Batch 1:  LOSS: 1.723 TEST_ACC: 36.486% VALIDACTION_ACC: 37.760%\n",
      "Epoch 32, CIFAR-10 Batch 1:  LOSS: 1.719 TEST_ACC: 36.149% VALIDACTION_ACC: 38.000%\n",
      "Epoch 33, CIFAR-10 Batch 1:  LOSS: 1.728 TEST_ACC: 36.824% VALIDACTION_ACC: 37.680%\n",
      "Epoch 34, CIFAR-10 Batch 1:  LOSS: 1.689 TEST_ACC: 37.500% VALIDACTION_ACC: 38.620%\n",
      "Epoch 35, CIFAR-10 Batch 1:  LOSS: 1.688 TEST_ACC: 34.459% VALIDACTION_ACC: 38.860%\n",
      "Epoch 36, CIFAR-10 Batch 1:  LOSS: 1.653 TEST_ACC: 40.878% VALIDACTION_ACC: 39.900%\n",
      "Epoch 37, CIFAR-10 Batch 1:  LOSS: 1.678 TEST_ACC: 36.486% VALIDACTION_ACC: 39.460%\n",
      "Epoch 38, CIFAR-10 Batch 1:  LOSS: 1.660 TEST_ACC: 38.176% VALIDACTION_ACC: 38.700%\n",
      "Epoch 39, CIFAR-10 Batch 1:  LOSS: 1.628 TEST_ACC: 36.486% VALIDACTION_ACC: 40.140%\n",
      "Epoch 40, CIFAR-10 Batch 1:  LOSS: 1.642 TEST_ACC: 39.527% VALIDACTION_ACC: 40.560%\n",
      "Epoch 41, CIFAR-10 Batch 1:  LOSS: 1.660 TEST_ACC: 39.527% VALIDACTION_ACC: 40.480%\n",
      "Epoch 42, CIFAR-10 Batch 1:  LOSS: 1.674 TEST_ACC: 40.878% VALIDACTION_ACC: 40.500%\n",
      "Epoch 43, CIFAR-10 Batch 1:  LOSS: 1.609 TEST_ACC: 41.554% VALIDACTION_ACC: 41.460%\n",
      "Epoch 44, CIFAR-10 Batch 1:  LOSS: 1.588 TEST_ACC: 41.892% VALIDACTION_ACC: 42.140%\n",
      "Epoch 45, CIFAR-10 Batch 1:  LOSS: 1.620 TEST_ACC: 43.919% VALIDACTION_ACC: 42.040%\n",
      "Epoch 46, CIFAR-10 Batch 1:  LOSS: 1.601 TEST_ACC: 43.581% VALIDACTION_ACC: 42.620%\n",
      "Epoch 47, CIFAR-10 Batch 1:  LOSS: 1.583 TEST_ACC: 44.932% VALIDACTION_ACC: 43.460%\n",
      "Epoch 48, CIFAR-10 Batch 1:  LOSS: 1.640 TEST_ACC: 41.554% VALIDACTION_ACC: 41.840%\n",
      "Epoch 49, CIFAR-10 Batch 1:  LOSS: 1.541 TEST_ACC: 44.257% VALIDACTION_ACC: 43.220%\n",
      "Epoch 50, CIFAR-10 Batch 1:  LOSS: 1.575 TEST_ACC: 42.905% VALIDACTION_ACC: 42.820%\n",
      "Epoch 51, CIFAR-10 Batch 1:  LOSS: 1.573 TEST_ACC: 43.581% VALIDACTION_ACC: 42.900%\n",
      "Epoch 52, CIFAR-10 Batch 1:  LOSS: 1.524 TEST_ACC: 46.959% VALIDACTION_ACC: 45.140%\n",
      "Epoch 53, CIFAR-10 Batch 1:  LOSS: 1.537 TEST_ACC: 43.243% VALIDACTION_ACC: 43.960%\n",
      "Epoch 54, CIFAR-10 Batch 1:  LOSS: 1.574 TEST_ACC: 43.919% VALIDACTION_ACC: 43.100%\n",
      "Epoch 55, CIFAR-10 Batch 1:  LOSS: 1.500 TEST_ACC: 44.595% VALIDACTION_ACC: 46.000%\n",
      "Epoch 56, CIFAR-10 Batch 1:  LOSS: 1.541 TEST_ACC: 45.946% VALIDACTION_ACC: 44.780%\n",
      "Epoch 57, CIFAR-10 Batch 1:  LOSS: 1.503 TEST_ACC: 44.257% VALIDACTION_ACC: 44.740%\n",
      "Epoch 58, CIFAR-10 Batch 1:  LOSS: 1.491 TEST_ACC: 47.297% VALIDACTION_ACC: 45.580%\n",
      "Epoch 59, CIFAR-10 Batch 1:  LOSS: 1.507 TEST_ACC: 47.297% VALIDACTION_ACC: 45.180%\n",
      "Epoch 60, CIFAR-10 Batch 1:  LOSS: 1.538 TEST_ACC: 42.905% VALIDACTION_ACC: 44.460%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  LOSS: 2.302 TEST_ACC: 15.541% VALIDACTION_ACC: 10.400%\n",
      "Epoch  1, CIFAR-10 Batch 2:  LOSS: 2.301 TEST_ACC: 10.135% VALIDACTION_ACC: 9.700%\n",
      "Epoch  1, CIFAR-10 Batch 3:  LOSS: 2.298 TEST_ACC: 12.500% VALIDACTION_ACC: 11.160%\n",
      "Epoch  1, CIFAR-10 Batch 4:  LOSS: 2.286 TEST_ACC: 9.459% VALIDACTION_ACC: 10.060%\n",
      "Epoch  1, CIFAR-10 Batch 5:  LOSS: 2.223 TEST_ACC: 10.811% VALIDACTION_ACC: 10.880%\n",
      "Epoch  2, CIFAR-10 Batch 1:  LOSS: 2.199 TEST_ACC: 18.581% VALIDACTION_ACC: 17.120%\n",
      "Epoch  2, CIFAR-10 Batch 2:  LOSS: 2.175 TEST_ACC: 23.649% VALIDACTION_ACC: 19.860%\n",
      "Epoch  2, CIFAR-10 Batch 3:  LOSS: 2.063 TEST_ACC: 21.959% VALIDACTION_ACC: 21.140%\n",
      "Epoch  2, CIFAR-10 Batch 4:  LOSS: 2.078 TEST_ACC: 23.649% VALIDACTION_ACC: 22.600%\n",
      "Epoch  2, CIFAR-10 Batch 5:  LOSS: 1.993 TEST_ACC: 27.027% VALIDACTION_ACC: 23.580%\n",
      "Epoch  3, CIFAR-10 Batch 1:  LOSS: 2.066 TEST_ACC: 20.608% VALIDACTION_ACC: 22.860%\n",
      "Epoch  3, CIFAR-10 Batch 2:  LOSS: 2.124 TEST_ACC: 18.581% VALIDACTION_ACC: 21.640%\n",
      "Epoch  3, CIFAR-10 Batch 3:  LOSS: 2.043 TEST_ACC: 20.946% VALIDACTION_ACC: 21.780%\n",
      "Epoch  3, CIFAR-10 Batch 4:  LOSS: 1.854 TEST_ACC: 32.432% VALIDACTION_ACC: 29.120%\n",
      "Epoch  3, CIFAR-10 Batch 5:  LOSS: 1.934 TEST_ACC: 29.054% VALIDACTION_ACC: 26.080%\n",
      "Epoch  4, CIFAR-10 Batch 1:  LOSS: 1.946 TEST_ACC: 26.351% VALIDACTION_ACC: 30.560%\n",
      "Epoch  4, CIFAR-10 Batch 2:  LOSS: 1.948 TEST_ACC: 29.054% VALIDACTION_ACC: 27.040%\n",
      "Epoch  4, CIFAR-10 Batch 3:  LOSS: 1.838 TEST_ACC: 35.811% VALIDACTION_ACC: 30.140%\n",
      "Epoch  4, CIFAR-10 Batch 4:  LOSS: 1.823 TEST_ACC: 35.811% VALIDACTION_ACC: 30.720%\n",
      "Epoch  4, CIFAR-10 Batch 5:  LOSS: 1.827 TEST_ACC: 35.135% VALIDACTION_ACC: 31.160%\n",
      "Epoch  5, CIFAR-10 Batch 1:  LOSS: 1.903 TEST_ACC: 31.757% VALIDACTION_ACC: 32.100%\n",
      "Epoch  5, CIFAR-10 Batch 2:  LOSS: 1.850 TEST_ACC: 31.419% VALIDACTION_ACC: 32.400%\n",
      "Epoch  5, CIFAR-10 Batch 3:  LOSS: 1.759 TEST_ACC: 38.851% VALIDACTION_ACC: 34.360%\n",
      "Epoch  5, CIFAR-10 Batch 4:  LOSS: 1.765 TEST_ACC: 35.811% VALIDACTION_ACC: 33.860%\n",
      "Epoch  5, CIFAR-10 Batch 5:  LOSS: 1.761 TEST_ACC: 37.162% VALIDACTION_ACC: 33.620%\n",
      "Epoch  6, CIFAR-10 Batch 1:  LOSS: 1.819 TEST_ACC: 35.135% VALIDACTION_ACC: 36.280%\n",
      "Epoch  6, CIFAR-10 Batch 2:  LOSS: 1.770 TEST_ACC: 33.108% VALIDACTION_ACC: 34.840%\n",
      "Epoch  6, CIFAR-10 Batch 3:  LOSS: 1.676 TEST_ACC: 40.203% VALIDACTION_ACC: 37.040%\n",
      "Epoch  6, CIFAR-10 Batch 4:  LOSS: 1.643 TEST_ACC: 39.865% VALIDACTION_ACC: 38.920%\n",
      "Epoch  6, CIFAR-10 Batch 5:  LOSS: 1.725 TEST_ACC: 40.878% VALIDACTION_ACC: 35.140%\n",
      "Epoch  7, CIFAR-10 Batch 1:  LOSS: 1.790 TEST_ACC: 39.527% VALIDACTION_ACC: 39.280%\n",
      "Epoch  7, CIFAR-10 Batch 2:  LOSS: 1.734 TEST_ACC: 35.811% VALIDACTION_ACC: 36.960%\n",
      "Epoch  7, CIFAR-10 Batch 3:  LOSS: 1.615 TEST_ACC: 42.568% VALIDACTION_ACC: 38.640%\n",
      "Epoch  7, CIFAR-10 Batch 4:  LOSS: 1.611 TEST_ACC: 41.554% VALIDACTION_ACC: 40.140%\n",
      "Epoch  7, CIFAR-10 Batch 5:  LOSS: 1.677 TEST_ACC: 41.216% VALIDACTION_ACC: 38.040%\n",
      "Epoch  8, CIFAR-10 Batch 1:  LOSS: 1.717 TEST_ACC: 41.216% VALIDACTION_ACC: 41.800%\n",
      "Epoch  8, CIFAR-10 Batch 2:  LOSS: 1.669 TEST_ACC: 38.851% VALIDACTION_ACC: 39.400%\n",
      "Epoch  8, CIFAR-10 Batch 3:  LOSS: 1.523 TEST_ACC: 45.946% VALIDACTION_ACC: 42.020%\n",
      "Epoch  8, CIFAR-10 Batch 4:  LOSS: 1.534 TEST_ACC: 46.622% VALIDACTION_ACC: 42.800%\n",
      "Epoch  8, CIFAR-10 Batch 5:  LOSS: 1.636 TEST_ACC: 42.905% VALIDACTION_ACC: 39.380%\n",
      "Epoch  9, CIFAR-10 Batch 1:  LOSS: 1.666 TEST_ACC: 43.243% VALIDACTION_ACC: 44.220%\n",
      "Epoch  9, CIFAR-10 Batch 2:  LOSS: 1.611 TEST_ACC: 42.905% VALIDACTION_ACC: 41.740%\n",
      "Epoch  9, CIFAR-10 Batch 3:  LOSS: 1.464 TEST_ACC: 50.000% VALIDACTION_ACC: 43.620%\n",
      "Epoch  9, CIFAR-10 Batch 4:  LOSS: 1.458 TEST_ACC: 47.635% VALIDACTION_ACC: 43.300%\n",
      "Epoch  9, CIFAR-10 Batch 5:  LOSS: 1.569 TEST_ACC: 43.581% VALIDACTION_ACC: 41.440%\n",
      "Epoch 10, CIFAR-10 Batch 1:  LOSS: 1.610 TEST_ACC: 44.257% VALIDACTION_ACC: 44.980%\n",
      "Epoch 10, CIFAR-10 Batch 2:  LOSS: 1.582 TEST_ACC: 41.216% VALIDACTION_ACC: 43.340%\n",
      "Epoch 10, CIFAR-10 Batch 3:  LOSS: 1.448 TEST_ACC: 48.986% VALIDACTION_ACC: 44.140%\n",
      "Epoch 10, CIFAR-10 Batch 4:  LOSS: 1.442 TEST_ACC: 49.662% VALIDACTION_ACC: 43.980%\n",
      "Epoch 10, CIFAR-10 Batch 5:  LOSS: 1.503 TEST_ACC: 44.932% VALIDACTION_ACC: 43.080%\n",
      "Epoch 11, CIFAR-10 Batch 1:  LOSS: 1.593 TEST_ACC: 43.919% VALIDACTION_ACC: 45.740%\n",
      "Epoch 11, CIFAR-10 Batch 2:  LOSS: 1.548 TEST_ACC: 43.243% VALIDACTION_ACC: 45.100%\n",
      "Epoch 11, CIFAR-10 Batch 3:  LOSS: 1.407 TEST_ACC: 50.676% VALIDACTION_ACC: 44.920%\n",
      "Epoch 11, CIFAR-10 Batch 4:  LOSS: 1.389 TEST_ACC: 51.014% VALIDACTION_ACC: 45.720%\n",
      "Epoch 11, CIFAR-10 Batch 5:  LOSS: 1.482 TEST_ACC: 46.959% VALIDACTION_ACC: 44.240%\n",
      "Epoch 12, CIFAR-10 Batch 1:  LOSS: 1.604 TEST_ACC: 41.216% VALIDACTION_ACC: 45.640%\n",
      "Epoch 12, CIFAR-10 Batch 2:  LOSS: 1.524 TEST_ACC: 43.581% VALIDACTION_ACC: 45.980%\n",
      "Epoch 12, CIFAR-10 Batch 3:  LOSS: 1.379 TEST_ACC: 49.662% VALIDACTION_ACC: 46.300%\n",
      "Epoch 12, CIFAR-10 Batch 4:  LOSS: 1.401 TEST_ACC: 49.324% VALIDACTION_ACC: 44.980%\n",
      "Epoch 12, CIFAR-10 Batch 5:  LOSS: 1.447 TEST_ACC: 47.297% VALIDACTION_ACC: 45.760%\n",
      "Epoch 13, CIFAR-10 Batch 1:  LOSS: 1.580 TEST_ACC: 42.905% VALIDACTION_ACC: 46.500%\n",
      "Epoch 13, CIFAR-10 Batch 2:  LOSS: 1.470 TEST_ACC: 45.608% VALIDACTION_ACC: 47.060%\n",
      "Epoch 13, CIFAR-10 Batch 3:  LOSS: 1.362 TEST_ACC: 52.365% VALIDACTION_ACC: 47.040%\n",
      "Epoch 13, CIFAR-10 Batch 4:  LOSS: 1.353 TEST_ACC: 52.703% VALIDACTION_ACC: 47.040%\n",
      "Epoch 13, CIFAR-10 Batch 5:  LOSS: 1.512 TEST_ACC: 46.284% VALIDACTION_ACC: 43.920%\n",
      "Epoch 14, CIFAR-10 Batch 1:  LOSS: 1.580 TEST_ACC: 42.568% VALIDACTION_ACC: 47.460%\n",
      "Epoch 14, CIFAR-10 Batch 2:  LOSS: 1.478 TEST_ACC: 44.257% VALIDACTION_ACC: 47.920%\n",
      "Epoch 14, CIFAR-10 Batch 3:  LOSS: 1.360 TEST_ACC: 48.649% VALIDACTION_ACC: 46.220%\n",
      "Epoch 14, CIFAR-10 Batch 4:  LOSS: 1.392 TEST_ACC: 51.351% VALIDACTION_ACC: 47.160%\n",
      "Epoch 14, CIFAR-10 Batch 5:  LOSS: 1.415 TEST_ACC: 49.662% VALIDACTION_ACC: 46.880%\n",
      "Epoch 15, CIFAR-10 Batch 1:  LOSS: 1.516 TEST_ACC: 47.297% VALIDACTION_ACC: 48.340%\n",
      "Epoch 15, CIFAR-10 Batch 2:  LOSS: 1.484 TEST_ACC: 45.946% VALIDACTION_ACC: 47.440%\n",
      "Epoch 15, CIFAR-10 Batch 3:  LOSS: 1.334 TEST_ACC: 51.689% VALIDACTION_ACC: 47.540%\n",
      "Epoch 15, CIFAR-10 Batch 4:  LOSS: 1.338 TEST_ACC: 53.378% VALIDACTION_ACC: 47.700%\n",
      "Epoch 15, CIFAR-10 Batch 5:  LOSS: 1.423 TEST_ACC: 49.324% VALIDACTION_ACC: 46.960%\n",
      "Epoch 16, CIFAR-10 Batch 1:  LOSS: 1.520 TEST_ACC: 44.595% VALIDACTION_ACC: 48.520%\n",
      "Epoch 16, CIFAR-10 Batch 2:  LOSS: 1.436 TEST_ACC: 47.297% VALIDACTION_ACC: 48.620%\n",
      "Epoch 16, CIFAR-10 Batch 3:  LOSS: 1.280 TEST_ACC: 54.054% VALIDACTION_ACC: 50.020%\n",
      "Epoch 16, CIFAR-10 Batch 4:  LOSS: 1.363 TEST_ACC: 49.324% VALIDACTION_ACC: 47.320%\n",
      "Epoch 16, CIFAR-10 Batch 5:  LOSS: 1.351 TEST_ACC: 54.392% VALIDACTION_ACC: 48.860%\n",
      "Epoch 17, CIFAR-10 Batch 1:  LOSS: 1.494 TEST_ACC: 47.297% VALIDACTION_ACC: 49.460%\n",
      "Epoch 17, CIFAR-10 Batch 2:  LOSS: 1.442 TEST_ACC: 47.973% VALIDACTION_ACC: 49.360%\n",
      "Epoch 17, CIFAR-10 Batch 3:  LOSS: 1.304 TEST_ACC: 54.392% VALIDACTION_ACC: 49.160%\n",
      "Epoch 17, CIFAR-10 Batch 4:  LOSS: 1.305 TEST_ACC: 52.703% VALIDACTION_ACC: 48.560%\n",
      "Epoch 17, CIFAR-10 Batch 5:  LOSS: 1.335 TEST_ACC: 53.716% VALIDACTION_ACC: 49.240%\n",
      "Epoch 18, CIFAR-10 Batch 1:  LOSS: 1.581 TEST_ACC: 43.581% VALIDACTION_ACC: 47.240%\n",
      "Epoch 18, CIFAR-10 Batch 2:  LOSS: 1.389 TEST_ACC: 50.000% VALIDACTION_ACC: 51.700%\n",
      "Epoch 18, CIFAR-10 Batch 3:  LOSS: 1.245 TEST_ACC: 54.054% VALIDACTION_ACC: 50.620%\n",
      "Epoch 18, CIFAR-10 Batch 4:  LOSS: 1.314 TEST_ACC: 53.378% VALIDACTION_ACC: 49.820%\n",
      "Epoch 18, CIFAR-10 Batch 5:  LOSS: 1.341 TEST_ACC: 51.689% VALIDACTION_ACC: 49.760%\n",
      "Epoch 19, CIFAR-10 Batch 1:  LOSS: 1.469 TEST_ACC: 46.959% VALIDACTION_ACC: 50.680%\n",
      "Epoch 19, CIFAR-10 Batch 2:  LOSS: 1.439 TEST_ACC: 48.649% VALIDACTION_ACC: 50.100%\n",
      "Epoch 19, CIFAR-10 Batch 3:  LOSS: 1.239 TEST_ACC: 56.081% VALIDACTION_ACC: 51.000%\n",
      "Epoch 19, CIFAR-10 Batch 4:  LOSS: 1.325 TEST_ACC: 50.000% VALIDACTION_ACC: 48.680%\n",
      "Epoch 19, CIFAR-10 Batch 5:  LOSS: 1.335 TEST_ACC: 53.041% VALIDACTION_ACC: 49.220%\n",
      "Epoch 20, CIFAR-10 Batch 1:  LOSS: 1.487 TEST_ACC: 48.311% VALIDACTION_ACC: 50.100%\n",
      "Epoch 20, CIFAR-10 Batch 2:  LOSS: 1.410 TEST_ACC: 49.324% VALIDACTION_ACC: 50.900%\n",
      "Epoch 20, CIFAR-10 Batch 3:  LOSS: 1.225 TEST_ACC: 55.405% VALIDACTION_ACC: 50.860%\n",
      "Epoch 20, CIFAR-10 Batch 4:  LOSS: 1.262 TEST_ACC: 56.419% VALIDACTION_ACC: 51.760%\n",
      "Epoch 20, CIFAR-10 Batch 5:  LOSS: 1.327 TEST_ACC: 51.689% VALIDACTION_ACC: 50.420%\n",
      "Epoch 21, CIFAR-10 Batch 1:  LOSS: 1.534 TEST_ACC: 46.284% VALIDACTION_ACC: 48.760%\n",
      "Epoch 21, CIFAR-10 Batch 2:  LOSS: 1.437 TEST_ACC: 47.635% VALIDACTION_ACC: 50.320%\n",
      "Epoch 21, CIFAR-10 Batch 3:  LOSS: 1.212 TEST_ACC: 54.730% VALIDACTION_ACC: 51.140%\n",
      "Epoch 21, CIFAR-10 Batch 4:  LOSS: 1.254 TEST_ACC: 55.743% VALIDACTION_ACC: 52.200%\n",
      "Epoch 21, CIFAR-10 Batch 5:  LOSS: 1.357 TEST_ACC: 52.027% VALIDACTION_ACC: 49.220%\n",
      "Epoch 22, CIFAR-10 Batch 1:  LOSS: 1.440 TEST_ACC: 50.000% VALIDACTION_ACC: 52.280%\n",
      "Epoch 22, CIFAR-10 Batch 2:  LOSS: 1.442 TEST_ACC: 48.649% VALIDACTION_ACC: 49.500%\n",
      "Epoch 22, CIFAR-10 Batch 3:  LOSS: 1.207 TEST_ACC: 55.405% VALIDACTION_ACC: 51.300%\n",
      "Epoch 22, CIFAR-10 Batch 4:  LOSS: 1.253 TEST_ACC: 55.743% VALIDACTION_ACC: 52.160%\n",
      "Epoch 22, CIFAR-10 Batch 5:  LOSS: 1.321 TEST_ACC: 52.027% VALIDACTION_ACC: 50.280%\n",
      "Epoch 23, CIFAR-10 Batch 1:  LOSS: 1.471 TEST_ACC: 48.986% VALIDACTION_ACC: 50.700%\n",
      "Epoch 23, CIFAR-10 Batch 2:  LOSS: 1.431 TEST_ACC: 48.986% VALIDACTION_ACC: 50.180%\n",
      "Epoch 23, CIFAR-10 Batch 3:  LOSS: 1.175 TEST_ACC: 56.081% VALIDACTION_ACC: 52.580%\n",
      "Epoch 23, CIFAR-10 Batch 4:  LOSS: 1.251 TEST_ACC: 55.743% VALIDACTION_ACC: 51.940%\n",
      "Epoch 23, CIFAR-10 Batch 5:  LOSS: 1.368 TEST_ACC: 52.703% VALIDACTION_ACC: 48.560%\n",
      "Epoch 24, CIFAR-10 Batch 1:  LOSS: 1.367 TEST_ACC: 53.041% VALIDACTION_ACC: 52.780%\n",
      "Epoch 24, CIFAR-10 Batch 2:  LOSS: 1.334 TEST_ACC: 51.689% VALIDACTION_ACC: 52.920%\n",
      "Epoch 24, CIFAR-10 Batch 3:  LOSS: 1.184 TEST_ACC: 55.743% VALIDACTION_ACC: 52.420%\n",
      "Epoch 24, CIFAR-10 Batch 4:  LOSS: 1.248 TEST_ACC: 56.081% VALIDACTION_ACC: 52.000%\n",
      "Epoch 24, CIFAR-10 Batch 5:  LOSS: 1.284 TEST_ACC: 55.743% VALIDACTION_ACC: 51.580%\n",
      "Epoch 25, CIFAR-10 Batch 1:  LOSS: 1.460 TEST_ACC: 47.973% VALIDACTION_ACC: 52.120%\n",
      "Epoch 25, CIFAR-10 Batch 2:  LOSS: 1.413 TEST_ACC: 48.649% VALIDACTION_ACC: 50.500%\n",
      "Epoch 25, CIFAR-10 Batch 3:  LOSS: 1.162 TEST_ACC: 56.419% VALIDACTION_ACC: 52.840%\n",
      "Epoch 25, CIFAR-10 Batch 4:  LOSS: 1.241 TEST_ACC: 55.743% VALIDACTION_ACC: 52.580%\n",
      "Epoch 25, CIFAR-10 Batch 5:  LOSS: 1.284 TEST_ACC: 54.730% VALIDACTION_ACC: 51.020%\n",
      "Epoch 26, CIFAR-10 Batch 1:  LOSS: 1.420 TEST_ACC: 49.324% VALIDACTION_ACC: 51.860%\n",
      "Epoch 26, CIFAR-10 Batch 2:  LOSS: 1.425 TEST_ACC: 47.297% VALIDACTION_ACC: 50.540%\n",
      "Epoch 26, CIFAR-10 Batch 3:  LOSS: 1.200 TEST_ACC: 54.392% VALIDACTION_ACC: 51.660%\n",
      "Epoch 26, CIFAR-10 Batch 4:  LOSS: 1.280 TEST_ACC: 54.392% VALIDACTION_ACC: 51.580%\n",
      "Epoch 26, CIFAR-10 Batch 5:  LOSS: 1.246 TEST_ACC: 56.081% VALIDACTION_ACC: 53.140%\n",
      "Epoch 27, CIFAR-10 Batch 1:  LOSS: 1.439 TEST_ACC: 51.351% VALIDACTION_ACC: 52.360%\n",
      "Epoch 27, CIFAR-10 Batch 2:  LOSS: 1.387 TEST_ACC: 48.649% VALIDACTION_ACC: 51.240%\n",
      "Epoch 27, CIFAR-10 Batch 3:  LOSS: 1.190 TEST_ACC: 54.054% VALIDACTION_ACC: 52.000%\n",
      "Epoch 27, CIFAR-10 Batch 4:  LOSS: 1.172 TEST_ACC: 59.122% VALIDACTION_ACC: 54.160%\n",
      "Epoch 27, CIFAR-10 Batch 5:  LOSS: 1.244 TEST_ACC: 55.405% VALIDACTION_ACC: 52.240%\n",
      "Epoch 28, CIFAR-10 Batch 1:  LOSS: 1.404 TEST_ACC: 51.014% VALIDACTION_ACC: 52.720%\n",
      "Epoch 28, CIFAR-10 Batch 2:  LOSS: 1.447 TEST_ACC: 47.635% VALIDACTION_ACC: 49.540%\n",
      "Epoch 28, CIFAR-10 Batch 3:  LOSS: 1.163 TEST_ACC: 58.108% VALIDACTION_ACC: 53.220%\n",
      "Epoch 28, CIFAR-10 Batch 4:  LOSS: 1.200 TEST_ACC: 56.757% VALIDACTION_ACC: 53.900%\n",
      "Epoch 28, CIFAR-10 Batch 5:  LOSS: 1.277 TEST_ACC: 56.419% VALIDACTION_ACC: 51.140%\n",
      "Epoch 29, CIFAR-10 Batch 1:  LOSS: 1.375 TEST_ACC: 52.365% VALIDACTION_ACC: 52.960%\n",
      "Epoch 29, CIFAR-10 Batch 2:  LOSS: 1.345 TEST_ACC: 51.689% VALIDACTION_ACC: 52.380%\n",
      "Epoch 29, CIFAR-10 Batch 3:  LOSS: 1.175 TEST_ACC: 56.081% VALIDACTION_ACC: 53.180%\n",
      "Epoch 29, CIFAR-10 Batch 4:  LOSS: 1.182 TEST_ACC: 57.095% VALIDACTION_ACC: 54.240%\n",
      "Epoch 29, CIFAR-10 Batch 5:  LOSS: 1.239 TEST_ACC: 55.743% VALIDACTION_ACC: 53.920%\n",
      "Epoch 30, CIFAR-10 Batch 1:  LOSS: 1.341 TEST_ACC: 53.041% VALIDACTION_ACC: 53.760%\n",
      "Epoch 30, CIFAR-10 Batch 2:  LOSS: 1.323 TEST_ACC: 52.703% VALIDACTION_ACC: 53.240%\n",
      "Epoch 30, CIFAR-10 Batch 3:  LOSS: 1.098 TEST_ACC: 60.473% VALIDACTION_ACC: 55.540%\n",
      "Epoch 30, CIFAR-10 Batch 4:  LOSS: 1.204 TEST_ACC: 57.432% VALIDACTION_ACC: 53.740%\n",
      "Epoch 30, CIFAR-10 Batch 5:  LOSS: 1.220 TEST_ACC: 56.757% VALIDACTION_ACC: 53.700%\n",
      "Epoch 31, CIFAR-10 Batch 1:  LOSS: 1.323 TEST_ACC: 55.068% VALIDACTION_ACC: 54.460%\n",
      "Epoch 31, CIFAR-10 Batch 2:  LOSS: 1.430 TEST_ACC: 48.311% VALIDACTION_ACC: 51.100%\n",
      "Epoch 31, CIFAR-10 Batch 3:  LOSS: 1.176 TEST_ACC: 53.716% VALIDACTION_ACC: 52.660%\n",
      "Epoch 31, CIFAR-10 Batch 4:  LOSS: 1.192 TEST_ACC: 57.432% VALIDACTION_ACC: 53.780%\n",
      "Epoch 31, CIFAR-10 Batch 5:  LOSS: 1.262 TEST_ACC: 56.081% VALIDACTION_ACC: 51.840%\n",
      "Epoch 32, CIFAR-10 Batch 1:  LOSS: 1.309 TEST_ACC: 54.730% VALIDACTION_ACC: 54.200%\n",
      "Epoch 32, CIFAR-10 Batch 2:  LOSS: 1.331 TEST_ACC: 50.676% VALIDACTION_ACC: 52.820%\n",
      "Epoch 32, CIFAR-10 Batch 3:  LOSS: 1.142 TEST_ACC: 58.446% VALIDACTION_ACC: 53.700%\n",
      "Epoch 32, CIFAR-10 Batch 4:  LOSS: 1.138 TEST_ACC: 60.135% VALIDACTION_ACC: 55.800%\n",
      "Epoch 32, CIFAR-10 Batch 5:  LOSS: 1.220 TEST_ACC: 57.770% VALIDACTION_ACC: 54.380%\n",
      "Epoch 33, CIFAR-10 Batch 1:  LOSS: 1.332 TEST_ACC: 54.054% VALIDACTION_ACC: 55.440%\n",
      "Epoch 33, CIFAR-10 Batch 2:  LOSS: 1.296 TEST_ACC: 51.351% VALIDACTION_ACC: 54.340%\n",
      "Epoch 33, CIFAR-10 Batch 3:  LOSS: 1.125 TEST_ACC: 58.108% VALIDACTION_ACC: 55.260%\n",
      "Epoch 33, CIFAR-10 Batch 4:  LOSS: 1.147 TEST_ACC: 58.446% VALIDACTION_ACC: 55.580%\n",
      "Epoch 33, CIFAR-10 Batch 5:  LOSS: 1.230 TEST_ACC: 55.405% VALIDACTION_ACC: 52.980%\n",
      "Epoch 34, CIFAR-10 Batch 1:  LOSS: 1.334 TEST_ACC: 53.378% VALIDACTION_ACC: 54.020%\n",
      "Epoch 34, CIFAR-10 Batch 2:  LOSS: 1.317 TEST_ACC: 51.014% VALIDACTION_ACC: 53.720%\n",
      "Epoch 34, CIFAR-10 Batch 3:  LOSS: 1.105 TEST_ACC: 59.122% VALIDACTION_ACC: 55.720%\n",
      "Epoch 34, CIFAR-10 Batch 4:  LOSS: 1.156 TEST_ACC: 58.108% VALIDACTION_ACC: 55.600%\n",
      "Epoch 34, CIFAR-10 Batch 5:  LOSS: 1.203 TEST_ACC: 58.108% VALIDACTION_ACC: 54.860%\n",
      "Epoch 35, CIFAR-10 Batch 1:  LOSS: 1.299 TEST_ACC: 54.054% VALIDACTION_ACC: 55.720%\n",
      "Epoch 35, CIFAR-10 Batch 2:  LOSS: 1.319 TEST_ACC: 50.338% VALIDACTION_ACC: 53.220%\n",
      "Epoch 35, CIFAR-10 Batch 3:  LOSS: 1.127 TEST_ACC: 58.446% VALIDACTION_ACC: 54.980%\n",
      "Epoch 35, CIFAR-10 Batch 4:  LOSS: 1.141 TEST_ACC: 58.446% VALIDACTION_ACC: 56.340%\n",
      "Epoch 35, CIFAR-10 Batch 5:  LOSS: 1.243 TEST_ACC: 56.757% VALIDACTION_ACC: 52.420%\n",
      "Epoch 36, CIFAR-10 Batch 1:  LOSS: 1.348 TEST_ACC: 52.027% VALIDACTION_ACC: 54.120%\n",
      "Epoch 36, CIFAR-10 Batch 2:  LOSS: 1.352 TEST_ACC: 50.676% VALIDACTION_ACC: 52.360%\n",
      "Epoch 36, CIFAR-10 Batch 3:  LOSS: 1.117 TEST_ACC: 58.446% VALIDACTION_ACC: 55.080%\n",
      "Epoch 36, CIFAR-10 Batch 4:  LOSS: 1.140 TEST_ACC: 59.797% VALIDACTION_ACC: 55.660%\n",
      "Epoch 36, CIFAR-10 Batch 5:  LOSS: 1.198 TEST_ACC: 56.419% VALIDACTION_ACC: 54.520%\n",
      "Epoch 37, CIFAR-10 Batch 1:  LOSS: 1.264 TEST_ACC: 55.068% VALIDACTION_ACC: 55.860%\n",
      "Epoch 37, CIFAR-10 Batch 2:  LOSS: 1.288 TEST_ACC: 52.027% VALIDACTION_ACC: 54.260%\n",
      "Epoch 37, CIFAR-10 Batch 3:  LOSS: 1.089 TEST_ACC: 60.811% VALIDACTION_ACC: 55.920%\n",
      "Epoch 37, CIFAR-10 Batch 4:  LOSS: 1.147 TEST_ACC: 58.784% VALIDACTION_ACC: 55.900%\n",
      "Epoch 37, CIFAR-10 Batch 5:  LOSS: 1.170 TEST_ACC: 60.473% VALIDACTION_ACC: 56.160%\n",
      "Epoch 38, CIFAR-10 Batch 1:  LOSS: 1.287 TEST_ACC: 56.081% VALIDACTION_ACC: 56.500%\n",
      "Epoch 38, CIFAR-10 Batch 2:  LOSS: 1.220 TEST_ACC: 55.405% VALIDACTION_ACC: 56.860%\n",
      "Epoch 38, CIFAR-10 Batch 3:  LOSS: 1.053 TEST_ACC: 62.838% VALIDACTION_ACC: 56.520%\n",
      "Epoch 38, CIFAR-10 Batch 4:  LOSS: 1.181 TEST_ACC: 57.432% VALIDACTION_ACC: 54.480%\n",
      "Epoch 38, CIFAR-10 Batch 5:  LOSS: 1.230 TEST_ACC: 56.081% VALIDACTION_ACC: 53.820%\n",
      "Epoch 39, CIFAR-10 Batch 1:  LOSS: 1.337 TEST_ACC: 53.716% VALIDACTION_ACC: 55.080%\n",
      "Epoch 39, CIFAR-10 Batch 2:  LOSS: 1.244 TEST_ACC: 53.041% VALIDACTION_ACC: 56.200%\n",
      "Epoch 39, CIFAR-10 Batch 3:  LOSS: 1.074 TEST_ACC: 59.797% VALIDACTION_ACC: 56.020%\n",
      "Epoch 39, CIFAR-10 Batch 4:  LOSS: 1.130 TEST_ACC: 57.770% VALIDACTION_ACC: 56.320%\n",
      "Epoch 39, CIFAR-10 Batch 5:  LOSS: 1.160 TEST_ACC: 59.797% VALIDACTION_ACC: 56.100%\n",
      "Epoch 40, CIFAR-10 Batch 1:  LOSS: 1.310 TEST_ACC: 53.041% VALIDACTION_ACC: 56.540%\n",
      "Epoch 40, CIFAR-10 Batch 2:  LOSS: 1.362 TEST_ACC: 50.676% VALIDACTION_ACC: 52.300%\n",
      "Epoch 40, CIFAR-10 Batch 3:  LOSS: 1.102 TEST_ACC: 59.459% VALIDACTION_ACC: 55.100%\n",
      "Epoch 40, CIFAR-10 Batch 4:  LOSS: 1.155 TEST_ACC: 57.770% VALIDACTION_ACC: 54.760%\n",
      "Epoch 40, CIFAR-10 Batch 5:  LOSS: 1.187 TEST_ACC: 59.122% VALIDACTION_ACC: 54.880%\n",
      "Epoch 41, CIFAR-10 Batch 1:  LOSS: 1.264 TEST_ACC: 56.419% VALIDACTION_ACC: 55.880%\n",
      "Epoch 41, CIFAR-10 Batch 2:  LOSS: 1.229 TEST_ACC: 54.392% VALIDACTION_ACC: 56.360%\n",
      "Epoch 41, CIFAR-10 Batch 3:  LOSS: 1.074 TEST_ACC: 58.108% VALIDACTION_ACC: 56.560%\n",
      "Epoch 41, CIFAR-10 Batch 4:  LOSS: 1.113 TEST_ACC: 60.811% VALIDACTION_ACC: 57.140%\n",
      "Epoch 41, CIFAR-10 Batch 5:  LOSS: 1.146 TEST_ACC: 60.473% VALIDACTION_ACC: 56.760%\n",
      "Epoch 42, CIFAR-10 Batch 1:  LOSS: 1.311 TEST_ACC: 53.716% VALIDACTION_ACC: 55.000%\n",
      "Epoch 42, CIFAR-10 Batch 2:  LOSS: 1.273 TEST_ACC: 51.689% VALIDACTION_ACC: 54.940%\n",
      "Epoch 42, CIFAR-10 Batch 3:  LOSS: 1.082 TEST_ACC: 60.811% VALIDACTION_ACC: 55.820%\n",
      "Epoch 42, CIFAR-10 Batch 4:  LOSS: 1.117 TEST_ACC: 62.162% VALIDACTION_ACC: 56.860%\n",
      "Epoch 42, CIFAR-10 Batch 5:  LOSS: 1.175 TEST_ACC: 60.473% VALIDACTION_ACC: 55.820%\n",
      "Epoch 43, CIFAR-10 Batch 1:  LOSS: 1.293 TEST_ACC: 55.405% VALIDACTION_ACC: 57.500%\n",
      "Epoch 43, CIFAR-10 Batch 2:  LOSS: 1.261 TEST_ACC: 54.054% VALIDACTION_ACC: 55.520%\n",
      "Epoch 43, CIFAR-10 Batch 3:  LOSS: 1.060 TEST_ACC: 61.486% VALIDACTION_ACC: 57.620%\n",
      "Epoch 43, CIFAR-10 Batch 4:  LOSS: 1.091 TEST_ACC: 61.486% VALIDACTION_ACC: 57.640%\n",
      "Epoch 43, CIFAR-10 Batch 5:  LOSS: 1.140 TEST_ACC: 61.149% VALIDACTION_ACC: 57.320%\n",
      "Epoch 44, CIFAR-10 Batch 1:  LOSS: 1.241 TEST_ACC: 56.419% VALIDACTION_ACC: 56.500%\n",
      "Epoch 44, CIFAR-10 Batch 2:  LOSS: 1.241 TEST_ACC: 55.743% VALIDACTION_ACC: 56.500%\n",
      "Epoch 44, CIFAR-10 Batch 3:  LOSS: 1.089 TEST_ACC: 59.459% VALIDACTION_ACC: 56.080%\n",
      "Epoch 44, CIFAR-10 Batch 4:  LOSS: 1.105 TEST_ACC: 62.162% VALIDACTION_ACC: 57.640%\n",
      "Epoch 44, CIFAR-10 Batch 5:  LOSS: 1.160 TEST_ACC: 64.527% VALIDACTION_ACC: 56.280%\n",
      "Epoch 45, CIFAR-10 Batch 1:  LOSS: 1.230 TEST_ACC: 58.784% VALIDACTION_ACC: 57.300%\n",
      "Epoch 45, CIFAR-10 Batch 2:  LOSS: 1.185 TEST_ACC: 59.122% VALIDACTION_ACC: 58.080%\n",
      "Epoch 45, CIFAR-10 Batch 3:  LOSS: 1.047 TEST_ACC: 62.838% VALIDACTION_ACC: 58.340%\n",
      "Epoch 45, CIFAR-10 Batch 4:  LOSS: 1.058 TEST_ACC: 63.514% VALIDACTION_ACC: 58.500%\n",
      "Epoch 45, CIFAR-10 Batch 5:  LOSS: 1.140 TEST_ACC: 62.162% VALIDACTION_ACC: 56.880%\n",
      "Epoch 46, CIFAR-10 Batch 1:  LOSS: 1.211 TEST_ACC: 60.135% VALIDACTION_ACC: 59.060%\n",
      "Epoch 46, CIFAR-10 Batch 2:  LOSS: 1.204 TEST_ACC: 55.743% VALIDACTION_ACC: 56.760%\n",
      "Epoch 46, CIFAR-10 Batch 3:  LOSS: 1.033 TEST_ACC: 62.500% VALIDACTION_ACC: 57.940%\n",
      "Epoch 46, CIFAR-10 Batch 4:  LOSS: 1.078 TEST_ACC: 61.149% VALIDACTION_ACC: 58.020%\n",
      "Epoch 46, CIFAR-10 Batch 5:  LOSS: 1.129 TEST_ACC: 62.162% VALIDACTION_ACC: 56.960%\n",
      "Epoch 47, CIFAR-10 Batch 1:  LOSS: 1.234 TEST_ACC: 56.419% VALIDACTION_ACC: 58.320%\n",
      "Epoch 47, CIFAR-10 Batch 2:  LOSS: 1.252 TEST_ACC: 54.730% VALIDACTION_ACC: 55.380%\n",
      "Epoch 47, CIFAR-10 Batch 3:  LOSS: 1.053 TEST_ACC: 61.824% VALIDACTION_ACC: 57.980%\n",
      "Epoch 47, CIFAR-10 Batch 4:  LOSS: 1.033 TEST_ACC: 66.216% VALIDACTION_ACC: 58.800%\n",
      "Epoch 47, CIFAR-10 Batch 5:  LOSS: 1.147 TEST_ACC: 60.473% VALIDACTION_ACC: 56.420%\n",
      "Epoch 48, CIFAR-10 Batch 1:  LOSS: 1.229 TEST_ACC: 54.730% VALIDACTION_ACC: 57.340%\n",
      "Epoch 48, CIFAR-10 Batch 2:  LOSS: 1.263 TEST_ACC: 53.378% VALIDACTION_ACC: 55.920%\n",
      "Epoch 48, CIFAR-10 Batch 3:  LOSS: 1.082 TEST_ACC: 59.797% VALIDACTION_ACC: 56.480%\n",
      "Epoch 48, CIFAR-10 Batch 4:  LOSS: 1.092 TEST_ACC: 62.500% VALIDACTION_ACC: 56.540%\n",
      "Epoch 48, CIFAR-10 Batch 5:  LOSS: 1.131 TEST_ACC: 61.486% VALIDACTION_ACC: 56.980%\n",
      "Epoch 49, CIFAR-10 Batch 1:  LOSS: 1.250 TEST_ACC: 55.743% VALIDACTION_ACC: 58.220%\n",
      "Epoch 49, CIFAR-10 Batch 2:  LOSS: 1.266 TEST_ACC: 54.054% VALIDACTION_ACC: 55.420%\n",
      "Epoch 49, CIFAR-10 Batch 3:  LOSS: 1.054 TEST_ACC: 60.473% VALIDACTION_ACC: 56.860%\n",
      "Epoch 49, CIFAR-10 Batch 4:  LOSS: 1.086 TEST_ACC: 60.811% VALIDACTION_ACC: 57.860%\n",
      "Epoch 49, CIFAR-10 Batch 5:  LOSS: 1.128 TEST_ACC: 62.838% VALIDACTION_ACC: 57.280%\n",
      "Epoch 50, CIFAR-10 Batch 1:  LOSS: 1.243 TEST_ACC: 56.757% VALIDACTION_ACC: 56.800%\n",
      "Epoch 50, CIFAR-10 Batch 2:  LOSS: 1.156 TEST_ACC: 58.446% VALIDACTION_ACC: 59.400%\n",
      "Epoch 50, CIFAR-10 Batch 3:  LOSS: 1.021 TEST_ACC: 63.176% VALIDACTION_ACC: 59.080%\n",
      "Epoch 50, CIFAR-10 Batch 4:  LOSS: 1.097 TEST_ACC: 60.473% VALIDACTION_ACC: 57.920%\n",
      "Epoch 50, CIFAR-10 Batch 5:  LOSS: 1.090 TEST_ACC: 62.500% VALIDACTION_ACC: 58.400%\n",
      "Epoch 51, CIFAR-10 Batch 1:  LOSS: 1.171 TEST_ACC: 59.459% VALIDACTION_ACC: 58.600%\n",
      "Epoch 51, CIFAR-10 Batch 2:  LOSS: 1.184 TEST_ACC: 57.095% VALIDACTION_ACC: 57.280%\n",
      "Epoch 51, CIFAR-10 Batch 3:  LOSS: 1.083 TEST_ACC: 58.446% VALIDACTION_ACC: 56.500%\n",
      "Epoch 51, CIFAR-10 Batch 4:  LOSS: 1.068 TEST_ACC: 62.838% VALIDACTION_ACC: 57.680%\n",
      "Epoch 51, CIFAR-10 Batch 5:  LOSS: 1.092 TEST_ACC: 63.514% VALIDACTION_ACC: 58.720%\n",
      "Epoch 52, CIFAR-10 Batch 1:  LOSS: 1.194 TEST_ACC: 58.108% VALIDACTION_ACC: 58.440%\n",
      "Epoch 52, CIFAR-10 Batch 2:  LOSS: 1.165 TEST_ACC: 58.108% VALIDACTION_ACC: 57.940%\n",
      "Epoch 52, CIFAR-10 Batch 3:  LOSS: 1.046 TEST_ACC: 61.824% VALIDACTION_ACC: 57.640%\n",
      "Epoch 52, CIFAR-10 Batch 4:  LOSS: 1.048 TEST_ACC: 63.176% VALIDACTION_ACC: 58.680%\n",
      "Epoch 52, CIFAR-10 Batch 5:  LOSS: 1.104 TEST_ACC: 63.176% VALIDACTION_ACC: 57.900%\n",
      "Epoch 53, CIFAR-10 Batch 1:  LOSS: 1.216 TEST_ACC: 60.811% VALIDACTION_ACC: 57.520%\n",
      "Epoch 53, CIFAR-10 Batch 2:  LOSS: 1.190 TEST_ACC: 56.419% VALIDACTION_ACC: 58.240%\n",
      "Epoch 53, CIFAR-10 Batch 3:  LOSS: 1.033 TEST_ACC: 61.486% VALIDACTION_ACC: 58.040%\n",
      "Epoch 53, CIFAR-10 Batch 4:  LOSS: 1.086 TEST_ACC: 62.162% VALIDACTION_ACC: 58.340%\n",
      "Epoch 53, CIFAR-10 Batch 5:  LOSS: 1.121 TEST_ACC: 61.824% VALIDACTION_ACC: 56.960%\n",
      "Epoch 54, CIFAR-10 Batch 1:  LOSS: 1.181 TEST_ACC: 60.811% VALIDACTION_ACC: 59.320%\n",
      "Epoch 54, CIFAR-10 Batch 2:  LOSS: 1.159 TEST_ACC: 55.743% VALIDACTION_ACC: 58.620%\n",
      "Epoch 54, CIFAR-10 Batch 3:  LOSS: 1.040 TEST_ACC: 62.162% VALIDACTION_ACC: 58.000%\n",
      "Epoch 54, CIFAR-10 Batch 4:  LOSS: 1.039 TEST_ACC: 63.176% VALIDACTION_ACC: 59.360%\n",
      "Epoch 54, CIFAR-10 Batch 5:  LOSS: 1.104 TEST_ACC: 61.824% VALIDACTION_ACC: 57.820%\n",
      "Epoch 55, CIFAR-10 Batch 1:  LOSS: 1.233 TEST_ACC: 56.757% VALIDACTION_ACC: 58.080%\n",
      "Epoch 55, CIFAR-10 Batch 2:  LOSS: 1.144 TEST_ACC: 59.459% VALIDACTION_ACC: 58.960%\n",
      "Epoch 55, CIFAR-10 Batch 3:  LOSS: 1.029 TEST_ACC: 61.824% VALIDACTION_ACC: 58.660%\n",
      "Epoch 55, CIFAR-10 Batch 4:  LOSS: 1.057 TEST_ACC: 61.824% VALIDACTION_ACC: 58.560%\n",
      "Epoch 55, CIFAR-10 Batch 5:  LOSS: 1.126 TEST_ACC: 62.162% VALIDACTION_ACC: 57.560%\n",
      "Epoch 56, CIFAR-10 Batch 1:  LOSS: 1.214 TEST_ACC: 57.432% VALIDACTION_ACC: 58.380%\n",
      "Epoch 56, CIFAR-10 Batch 2:  LOSS: 1.151 TEST_ACC: 59.122% VALIDACTION_ACC: 59.300%\n",
      "Epoch 56, CIFAR-10 Batch 3:  LOSS: 1.018 TEST_ACC: 64.189% VALIDACTION_ACC: 58.860%\n",
      "Epoch 56, CIFAR-10 Batch 4:  LOSS: 1.021 TEST_ACC: 65.878% VALIDACTION_ACC: 59.520%\n",
      "Epoch 56, CIFAR-10 Batch 5:  LOSS: 1.093 TEST_ACC: 62.838% VALIDACTION_ACC: 58.240%\n",
      "Epoch 57, CIFAR-10 Batch 1:  LOSS: 1.225 TEST_ACC: 55.743% VALIDACTION_ACC: 57.900%\n",
      "Epoch 57, CIFAR-10 Batch 2:  LOSS: 1.194 TEST_ACC: 56.419% VALIDACTION_ACC: 57.880%\n",
      "Epoch 57, CIFAR-10 Batch 3:  LOSS: 1.062 TEST_ACC: 59.459% VALIDACTION_ACC: 57.000%\n",
      "Epoch 57, CIFAR-10 Batch 4:  LOSS: 1.118 TEST_ACC: 60.473% VALIDACTION_ACC: 57.300%\n",
      "Epoch 57, CIFAR-10 Batch 5:  LOSS: 1.088 TEST_ACC: 63.176% VALIDACTION_ACC: 58.920%\n",
      "Epoch 58, CIFAR-10 Batch 1:  LOSS: 1.226 TEST_ACC: 56.757% VALIDACTION_ACC: 59.080%\n",
      "Epoch 58, CIFAR-10 Batch 2:  LOSS: 1.138 TEST_ACC: 58.108% VALIDACTION_ACC: 59.180%\n",
      "Epoch 58, CIFAR-10 Batch 3:  LOSS: 1.023 TEST_ACC: 62.500% VALIDACTION_ACC: 58.460%\n",
      "Epoch 58, CIFAR-10 Batch 4:  LOSS: 1.073 TEST_ACC: 62.838% VALIDACTION_ACC: 58.540%\n",
      "Epoch 58, CIFAR-10 Batch 5:  LOSS: 1.078 TEST_ACC: 61.486% VALIDACTION_ACC: 59.020%\n",
      "Epoch 59, CIFAR-10 Batch 1:  LOSS: 1.144 TEST_ACC: 61.149% VALIDACTION_ACC: 60.400%\n",
      "Epoch 59, CIFAR-10 Batch 2:  LOSS: 1.143 TEST_ACC: 60.473% VALIDACTION_ACC: 59.300%\n",
      "Epoch 59, CIFAR-10 Batch 3:  LOSS: 1.004 TEST_ACC: 63.514% VALIDACTION_ACC: 59.900%\n",
      "Epoch 59, CIFAR-10 Batch 4:  LOSS: 1.029 TEST_ACC: 62.500% VALIDACTION_ACC: 59.220%\n",
      "Epoch 59, CIFAR-10 Batch 5:  LOSS: 1.078 TEST_ACC: 62.838% VALIDACTION_ACC: 59.240%\n",
      "Epoch 60, CIFAR-10 Batch 1:  LOSS: 1.182 TEST_ACC: 58.446% VALIDACTION_ACC: 59.580%\n",
      "Epoch 60, CIFAR-10 Batch 2:  LOSS: 1.158 TEST_ACC: 58.446% VALIDACTION_ACC: 58.980%\n",
      "Epoch 60, CIFAR-10 Batch 3:  LOSS: 1.014 TEST_ACC: 62.500% VALIDACTION_ACC: 58.860%\n",
      "Epoch 60, CIFAR-10 Batch 4:  LOSS: 1.059 TEST_ACC: 63.851% VALIDACTION_ACC: 59.480%\n",
      "Epoch 60, CIFAR-10 Batch 5:  LOSS: 1.075 TEST_ACC: 63.514% VALIDACTION_ACC: 59.360%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.58125\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2d2053c45c0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
